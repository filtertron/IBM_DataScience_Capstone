{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Data Science Final Capstone Project: \n",
    "\n",
    "# Safer Dining in Toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction/Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Basic Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is rooted in experience.  Some years ago our family vacationed on Anna Maria Island in Florida, USA.  Once we were settled in the hotel we sought and found a local beach restaurant with a full parking lot, on the theory that if so many other people thought it was a good restaurant, we probably would too.  I ordered what were described as \"conch fritters.\"  This turned out to be a serious mistake.  Within 8 hours I was violently ill and was confined to the hotel room for the entire 8 days we had planned to stay.\n",
    "One learning from this experience was: a full parking lot does not necessarily imply a good, or even a safe, dining experience.  Another was: it might have been very helpful to have known the restaurant's history with local health authorities, as well as any reviews other patrons had shared, before digging in to those conch fritters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is a proof of concept demonstration that uses both a proprietary fee-for-data service, Foursquare, and a public dataset called Dinesafe made freely available by the City of Toronto.  The objectives of the project (aside from satisfying the requirements of the IBM Data Science Professional Certificate Program) are two:\n",
    "\n",
    "1) demonstrate the ease of blending proprietary and public data to address a real-life need\n",
    "\n",
    "2) create an extensible proof of concept data layer for a proposed web application. This application would deliver venue-specific data, sourced from Foursquare and the Toronto Public Health Food Premises Inspection and Disclosure database, to several audiences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audiences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential audiences envisioned for this proof of concept are four:\n",
    "\n",
    "1) Toronto visitors and residents who want to reduce the probability of food-borne illness when patronizing Toronto food and drink venues\n",
    "\n",
    "2) Hoteliers and other tourist industry recommenders who seek to guide inquirers to high-quality, safe venues\n",
    "\n",
    "3) Owners and operators of food and drink venues who want to know what potential customers will learn about their establishments, and what actual customers have said about them\n",
    "\n",
    "4) Toronto authorities whose jurisdictions include tourism, marketing, and public health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monetization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project when and if deployed as a publicly-available web application will be funded through advertising.  It is anticipated that the bulk of advertsiing revenue will come from tourist destinations of all kinds in the Toronto area.  The same concept can be implemented anywhere the necessary data is available, not just in Toronto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted above, data sources for this proof of concept project are two:\n",
    "    \n",
    "1) Foursquare (https://foursquare.com/), in the company's words \"a location technology platform dedicated to improving how people move through the real world.\"  Data is accessed via the Foursquare published API, and returned in JSON format.  A developer-level account at minimum is required for genuinely usable data access.\n",
    "\n",
    "    a) Raw data sample (will be filtered to return only food and drink venues, supplied only to show format): \n",
    "    [  \n",
    "       {  \n",
    "          \"reasons\":{  \n",
    "             \"count\":0,\n",
    "             \"items\":[  \n",
    "                {  \n",
    "                   \"summary\":\"This spot is popular\",\n",
    "                   \"type\":\"general\",\n",
    "                   \"reasonName\":\"globalInteractionReason\"\n",
    "                }\n",
    "             ]\n",
    "          },\n",
    "          \"venue\":{  \n",
    "             \"id\":\"57524de4498e4f2143e9c292\",\n",
    "             \"name\":\"Rex Pak Food Packaging Ltd\",\n",
    "             \"location\":{  \n",
    "                \"address\":\"85 Thornmount Dr\",\n",
    "                \"lat\":43.805459,\n",
    "                \"lng\":-79.194344,\n",
    "                \"labeledLatLngs\":[  \n",
    "                   {  \n",
    "                      \"label\":\"display\",\n",
    "                      \"lat\":43.805459,\n",
    "                      \"lng\":-79.194344\n",
    "                   }\n",
    "                ],\n",
    "                \"distance\":136,\n",
    "                \"postalCode\":\"M1B 5V3\",\n",
    "                \"cc\":\"CA\",\n",
    "                \"city\":\"Scarborough\",\n",
    "                \"state\":\"ON\",\n",
    "                \"country\":\"Canada\",\n",
    "                \"formattedAddress\":[  \n",
    "                   \"85 Thornmount Dr\",\n",
    "                   \"Scarborough ON M1B 5V3\",\n",
    "                   \"Canada\"\n",
    "                ]\n",
    "             },\n",
    "             \"categories\":[  \n",
    "                {  \n",
    "                   \"id\":\"5453de49498eade8af355881\",\n",
    "                   \"name\":\"Business Service\",\n",
    "                   \"pluralName\":\"Business Services\",\n",
    "                   \"shortName\":\"Business Services\",\n",
    "                   \"icon\":{  \n",
    "                      \"prefix\":\"https://ss3.4sqi.net/img/categories_v2/building/default_\",\n",
    "                      \"suffix\":\".png\"\n",
    "                   },\n",
    "                   \"primary\":True\n",
    "                }\n",
    "             ],\n",
    "             \"photos\":{  \n",
    "                \"count\":0,\n",
    "                \"groups\":[  \n",
    "\n",
    "                ]\n",
    "             }\n",
    "          },\n",
    "          \"referralId\":\"e-0-57524de4498e4f2143e9c292-0\"\n",
    "       }\n",
    "    ]\n",
    "\n",
    "2) Dinesafe (https://open.toronto.ca/dataset/dinesafe/), that the City of Toronto describes as a \"snapshot of the information to the public concerning the Toronto Public Health Food Premises Inspection and Disclosure system.\"  Data is accessed via URL and returned in XML format.  \n",
    "\n",
    "    a) Raw data sample (supplied only to show format):\n",
    "    \n",
    "        <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "        <DINESAFE_DATA>\n",
    "           <ESTABLISHMENT>\n",
    "              <ID>9008018</ID>\n",
    "              <NAME>'K' STORE</NAME>\n",
    "              <TYPE>Food Store (Convenience/Variety)</TYPE>\n",
    "              <ADDRESS>99 CARLTON ST</ADDRESS>\n",
    "              <LATITUDE>43.66205</LATITUDE>\n",
    "              <LONGITUDE>-79.37747</LONGITUDE>\n",
    "              <STATUS>Pass</STATUS>\n",
    "              <INSPECTION>\n",
    "                 <STATUS>Pass</STATUS>\n",
    "                 <DATE>2018-03-02</DATE>\n",
    "                 <INFRACTION>\n",
    "                    <SEVERITY>NA - Not Applicable</SEVERITY>\n",
    "                    <ACTION>Notice to Comply</ACTION>\n",
    "                    <CONVICTION_DATE />\n",
    "                    <COURT_OUTCOME />\n",
    "                    <AMOUNT_FINED />\n",
    "                 </INFRACTION>\n",
    "              </INSPECTION>\n",
    "              <INSPECTION>\n",
    "                 <STATUS>Pass</STATUS>\n",
    "                 <DATE>2019-03-29</DATE>\n",
    "              </INSPECTION>\n",
    "           </ESTABLISHMENT>\n",
    "        </DINESAFE_DATA>\n",
    "        \n",
    "    b) Dinesafe data dictionary:\n",
    "        \n",
    "        ROW_ID - Represents the Row Number\n",
    "        ESTABLISHMENT_ID - Unique identifier for an establishment\n",
    "        INSPECTION_ID - Unique identifier for each Inspection\n",
    "        ESTABLISHMENT_NAME - Business name of the establishment\n",
    "        ESTABLISHMENTTYPE - Establishment type ie restaurant, mobile cart\n",
    "        ESTABLISHMENT_ADDRESS - Municipal address of the establishment\n",
    "        LONG/LAT - Longitude & Latitude coordinates of an establishment\n",
    "        ESTABLISHMENT_STATUS - Pass, Conditional Pass, Closed\n",
    "        MINIMUMINSPECTIONSPERYEAR - Every eating and drinking establishment in the City of Toronto receives a minimum of 1, 2, or 3 inspections each year depending on the specific type of establishment, \n",
    "                                    the food preparation processes, volume and type of food served and other related criteria. Low risk premises that offer for sale only pre-packaged non-hazardous food \n",
    "                                    shall be inspected once every two years. The inspection frequency for these low risk premises is shown as \"O\" (Other) on the report and in the data set\n",
    "        INFRACTION_DETAILS - Description of the Infraction\n",
    "        INSPECTION_DATE - Calendar date the inspection was conducted\n",
    "        SEVERITY - Level of the infraction, i.e. S - Significant, M - Minor, C - Crucial\n",
    "        ACTION - Enforcement activity based on the infractions noted during a food safety inspection\n",
    "        COURT_OUTCOME - The registered court decision resulting from the issuance of a ticket or summons for outstanding infractions to the Health Protection and Promotion Act\n",
    "        AMOUNT_FINED - Fine determined in a court outcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceed as we have done in preceding projects: load required libraries and get our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Toronto venues from Foursquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'groups'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f2fbbc547239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    154\u001b[0m toronto_venues = getNearbyVenues(names=toronto_pc_gc_df['Neighbourhood'],\n\u001b[0;32m    155\u001b[0m                                    \u001b[0mlatitudes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoronto_pc_gc_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Latitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                                    \u001b[0mlongitudes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoronto_pc_gc_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m                                   )\n",
      "\u001b[1;32m<ipython-input-5-f2fbbc547239>\u001b[0m in \u001b[0;36mgetNearbyVenues\u001b[1;34m(names, latitudes, longitudes, radius)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# make the GET request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"response\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'groups'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'items'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# return only relevant information for each nearby venue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'groups'"
     ]
    }
   ],
   "source": [
    "# uncomment these installations as may be required in a given ennvironment\n",
    "#install the necessary packages\n",
    "#commented out here to clean up the notebook\n",
    "#!pip install bs4;\n",
    "#!pip install requests;\n",
    "#!pip install lxml;\n",
    "#!pip install cchardet;\n",
    "\n",
    "#import the necessary libraries\n",
    "import urllib;\n",
    "import pandas as pd;\n",
    "from bs4 import BeautifulSoup;\n",
    "import numpy as np;\n",
    "import requests;\n",
    "import json;\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "#!pip install geopy --quiet; \n",
    "from geopy.geocoders import Nominatim; # convert an address into latitude and longitude values\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm;\n",
    "import matplotlib.colors as colors;\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans;\n",
    "\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you need Foursquare API installed\n",
    "import folium; # map rendering library\n",
    "\n",
    "#set the url to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M';\n",
    "\n",
    "#and you may ask yourself \"how do I know these are Toronto postal codes?\"\n",
    "#answer: because they have the first letter M.\n",
    "\n",
    "#get the parsed text from the url using the lxml parser\n",
    "html = urllib.request.urlopen(url);\n",
    "bs = BeautifulSoup(html,'lxml');\n",
    "\n",
    "#use BeautifulSoup4 to find the table we need\n",
    "table_object = bs.find(lambda tag: tag.name=='table',attrs={\"class\": \"wikitable sortable\"}); \n",
    "\n",
    "#use BeautifulSoup4 to get all rows in the table\n",
    "row_objects = table_object.tbody.find_all(lambda tag: tag.name=='tr');\n",
    "\n",
    "#create and populate a list to stage the data for pandas\n",
    "toronto_data_row_list = [];\n",
    "\n",
    "#define a function to get rows by tag (is it header or data?)\n",
    "def get_rows_by_tag(tr, column_tag='td'): # td (data) or th (header)       \n",
    "        return [td.get_text(strip=True) for td in tr.find_all(column_tag)];\n",
    "\n",
    "#append the header row to the list\n",
    "toronto_headers = get_rows_by_tag(row_objects[0], 'th');\n",
    "toronto_data_row_list.append(toronto_headers);\n",
    "\n",
    "#append the data rows to the list\n",
    "for tr in row_objects:\n",
    "    toronto_data_row_list.append(get_rows_by_tag(tr, 'td'));\n",
    "\n",
    "#use pandas to create a dataframe from the list\n",
    "toronto_pc_df = pd.DataFrame(toronto_data_row_list[1:], columns=toronto_data_row_list[0]);\n",
    "\n",
    "#delete rows with null Postcode\n",
    "toronto_pc_df = toronto_pc_df[toronto_pc_df.Postcode.notnull()] \n",
    "\n",
    "#delete rows with Borough = 'Not assigned'\n",
    "toronto_pc_df = toronto_pc_df[toronto_pc_df.Borough != 'Not assigned'];\n",
    "\n",
    "#aggregate rows with the same Postcode and Borough to create a comma-delimited Neighbourhood column\n",
    "toronto_pc_df = toronto_pc_df.groupby(['Postcode']).  \\\n",
    "    agg({'Borough' : 'first' , 'Neighbourhood' : ', '.join})  \\\n",
    "   .reset_index()  \\\n",
    "   .reindex(columns = toronto_pc_df.columns);\n",
    "\n",
    "#rename Postcode column to PostalCode as shown in assignment\n",
    "toronto_pc_df.rename(columns = {'Postcode' : 'PostalCode'}, inplace = True);\n",
    "\n",
    "#where 'Neighbourhood' is Not assigned, copy the Borough to Neighbourhood\n",
    "toronto_pc_df.loc[(toronto_pc_df.Neighbourhood=='Not assigned'), 'Neighbourhood'] = toronto_pc_df.Borough;\n",
    "\n",
    "#long and repeated attempts to use geocoder failed miserably, completely useless\n",
    "#now shifting to the downloaded csv file.\n",
    "\n",
    "#ingest the data from the csv file into a pandas dataframe\n",
    "#note that the original Postal Code column name was changed to PostalCode using Excel\n",
    "#the csv file was downloaded to the development Windows workstation.\n",
    "toronto_gc_df = pd.read_csv('C:/Users/mike/Desktop/Geospatial_Coordinates.csv', sep = ',');\n",
    "\n",
    "#merge the original dataframe with the geocode dataframe joining on PostalCode\n",
    "toronto_pc_gc_df = pd.merge(toronto_pc_df, toronto_gc_df, on='PostalCode');\n",
    "\n",
    "# go through the required song and dance to access Foursquare\n",
    "CLIENT_ID = 'XWT3TKOHVZGYK01HQXA55GEVK0ELBASPAATUMIEZZUU0O4TZ'; #  Foursquare ID\n",
    "CLIENT_SECRET = '1BSG4SRZIW4GRSPXJ4Q5DR0BQ0FWMWGP4XJYP02WYPM2ITQ'; #  Foursquare Secret\n",
    "TheMagicToken = 'TVUYECOF53QZZCSQOQ4QPQ55LZRW2SKDJNIE5VUWJCGFLFIY'; # Foursquare OAuth token\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "# function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name'];\n",
    "    \n",
    "LIMIT = 50; # limit of number of venues returned by Foursquare API\n",
    "radius = 500; # define radius from neighborhood centroid in meters\n",
    "\n",
    "# function to get venues within walking distance of a given neighborhood centroid\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=300):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&oauth_token={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            TheMagicToken,\n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues);\n",
    "    \n",
    "toronto_venues = getNearbyVenues(names=toronto_pc_gc_df['Neighbourhood'],\n",
    "                                   latitudes=toronto_pc_gc_df['Latitude'],\n",
    "                                   longitudes=toronto_pc_gc_df['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see that data returned as expected\n",
    "toronto_venues.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Toronto Dinesafe dataset from Toronto Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ckan0.cf.opendata.inter.prod-toronto.ca/download_resource/c3ebef25-177b-4adc-9c47-8763b04a52fb\n",
    "\n",
    "url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca/download_resource/c3ebef25-177b-4adc-9c47-8763b04a52fb\"\n",
    "\n",
    "# get url content\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response,'lxml')\n",
    "\n",
    "with open('DinesafeRaw.xml', 'w+') as f:\n",
    "    f.write(str(soup))\n",
    "\n",
    "#example node in Toronto Dinesafe XML result\n",
    "#<ESTABLISHMENT>\n",
    "#          <ID>9008018</ID>\n",
    "#          <NAME>'K' STORE</NAME>\n",
    "#          <TYPE>Food Store (Convenience/Variety)</TYPE>\n",
    "#          <ADDRESS>99 CARLTON ST</ADDRESS>\n",
    "#          <LATITUDE>43.66205</LATITUDE>\n",
    "#          <LONGITUDE>-79.37747</LONGITUDE>\n",
    "#          <STATUS>Pass</STATUS>\n",
    "#          <INSPECTION>\n",
    "#             <STATUS>Pass</STATUS>\n",
    "#             <DATE>2018-03-02</DATE>\n",
    "#             <INFRACTION>\n",
    "#             <SEVERITY>NA - Not Applicable</SEVERITY>\n",
    "#             <ACTION>Notice to Comply</ACTION>\n",
    "#             <CONVICTION_DATE />\n",
    "#             <COURT_OUTCOME />\n",
    "#             <AMOUNT_FINED />\n",
    "#             </INFRACTION>\n",
    "#           </INSPECTION>\n",
    "#           <INSPECTION>\n",
    "#              <STATUS>Pass</STATUS>\n",
    "#              <DATE>2019-03-29</DATE>\n",
    "#           </INSPECTION>\n",
    "#  </ESTABLISHMENT>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60519, 14)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten the 3-level nested Dinesafe XML result into a pandas dataframe, loop-de-loop-de-loop\n",
    "#using ElementTree for convenience\n",
    "\n",
    "#because we will merge this dataset with the postal code dataset created above, for simplicity we use a single Big Flat Table.\n",
    "\n",
    "#note that the Toronto Dinesafe data contain certain characters that make the raw xml unusable in UTF-8 encoding\n",
    "#these include É (00C9), é (00E9), and Ä (00C4)\n",
    "#for now these were manually substituted using Altova XMLSpy 2020.  XMLSpy was also used to prettify the XML result.  Need to do that in native Python.\n",
    "\n",
    "#Dinesafe.xml was cleaned up externally, not in this notebook, in this version as of 202002261955 UTC -4.\n",
    "\n",
    "tree = ET.parse('C:/Users/mike/Desktop/Dinesafe.xml');\n",
    "root = tree.getroot();\n",
    "estRow = [];\n",
    "allEstRows = [];\n",
    "for e in root.iter('establishment'):\n",
    "    estID = e.find('id').text\n",
    "    estName = e.find('name').text\n",
    "    estType = e.find('type').text\n",
    "    estAddr = e.find('address').text\n",
    "    estLat = e.find('latitude').text\n",
    "    estLong = e.find('longitude').text\n",
    "    estStat = e.find('status').text\n",
    "    for insp in e.iter('inspection'):\n",
    "        inspStat = insp.find('status').text\n",
    "        inspDate = insp.find('date').text\n",
    "        for infr in insp.iter('infraction'):\n",
    "            infrSeverity = infr.find('severity').text\n",
    "            infrAction = infr.find('action').text\n",
    "            infrConvDate = infr.find('conviction_date').text\n",
    "            infrCrtOutcome = infr.find('court_outcome').text\n",
    "            infrAmtFined = infr.find('amount_fined').text\n",
    "            estRow = [estID,estName,estType,estAddr,estLat,estLong,estStat,inspDate,inspStat,infrSeverity,infrAction,infrCrtOutcome,infrConvDate,infrAmtFined]\n",
    "            allEstRows.append(estRow)\n",
    "                  \n",
    "dfDinesafe = pd.DataFrame(allEstRows,columns=['Establishment_ID','Establishment_Name','Establishment_Type','Establishment_Addr','Establishment_Lat','Establishment_Long','Establishment_Current_Status','Inspection_Date','Inspection_Status','Infraction_Severity','Infraction_Action_Taken','Infraction_Court_Outcome','Infraction_Conviction_Date','Infraction_Aount_Fined']);       \n",
    "#check the result: are we good?\n",
    "dfDinesafe.head(60)\n",
    "#yes!\n",
    "dfDinesafe.shape #60519 records for about 17,000 establishments, not all of which still exist as of 202002261955 UTC -4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
